<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="/assets/xslt/atom.xslt" ?>
<?xml-stylesheet type="text/css" href="/assets/css/atom.css" ?>
<feed xmlns="http://www.w3.org/2005/Atom">
	<id>https://moeenahamd.github.io/</id>
	<title>Amged Rustom</title>
	<updated>2025-02-22T07:26:33+05:00</updated>

	<subtitle>»Feeling Responsive« is a responsive theme for Jekyll based on the fabulous foundation framework with beautiful typography and a bright color palette.</subtitle>

	
		
		<author>
			
				<name>Phlow</name>
			
			
			
				<uri>http://phlow.de/</uri>
			
		</author>
	

	<link href="https://moeenahamd.github.io/atom.xml" rel="self" type="application/rss+xml" />
	<link href="https://moeenahamd.github.io/" rel="alternate" type="text/html" />

	<generator uri="http://jekyllrb.com" version="4.4.1">Jekyll</generator>

	
		<entry>
			<id>https://moeenahamd.github.io/2014/12/cron-job-log-page-improvements/</id>
			<title>Cron Job Log Page Improvements</title>
			<link href="https://moeenahamd.github.io/2014/12/cron-job-log-page-improvements/" rel="alternate" type="text/html" title="Cron Job Log Page Improvements" />
			<updated>2014-12-29T00:00:00+05:00</updated>

			
				
				<author>
					
						<name>Phlow</name>
					
					
					
						<uri>http://phlow.de/</uri>
					
				</author>
			
			<summary>This recent Cronless update brings the following improvements to the log pages of cron jobs: Both free and premium members can now view all the logs without any restrictions. The export feature (available to premium members) now exports up to 100,000 records</summary>
			<content type="html" xml:base="https://moeenahamd.github.io/2014/12/cron-job-log-page-improvements/">&lt;p&gt;This recent &lt;a href=&quot;https://cronless.com/&quot;&gt;Cronless&lt;/a&gt; update brings the following improvements to the log pages of cron jobs:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Both free and premium members can now view all the logs without any restrictions.&lt;/li&gt;
  &lt;li&gt;The export feature (available to premium members) now exports up to 100,000 records.&lt;/li&gt;
  &lt;li&gt;The export feature (available to premium members) now exports to JSON file format.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Please note that to keep the website and the back-end server responsive and manageable we only keep log records that are less than a year old. So all the log records, whether listed on the page or exported, will be limited to that period of time.&lt;/p&gt;
</content>

			
				<category term="Announcements" />
			
			

			<published>2014-12-29T00:00:00+05:00</published>
		</entry>
	
		<entry>
			<id>https://moeenahamd.github.io/2014/05/cronless-bug-fixes-tweaks/</id>
			<title>Cronless Bug Fixes &amp; Tweaks</title>
			<link href="https://moeenahamd.github.io/2014/05/cronless-bug-fixes-tweaks/" rel="alternate" type="text/html" title="Cronless Bug Fixes &amp; Tweaks" />
			<updated>2014-05-05T00:00:00+05:00</updated>

			
				
				<author>
					
						<name>Phlow</name>
					
					
					
						<uri>http://phlow.de/</uri>
					
				</author>
			
			<summary>Todays updates include a few bug fixes and UI changes. Bug Fixes: The cron jobs user-agent field (available to Power and Pro members) now works as expected with all major web servers.</summary>
			<content type="html" xml:base="https://moeenahamd.github.io/2014/05/cronless-bug-fixes-tweaks/">&lt;h2 id=&quot;bug-fixes&quot;&gt;Bug Fixes&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;The cron jobs user-agent field (available to Power and Pro members) now works as expected with all major web servers.&lt;/li&gt;
  &lt;li&gt;The Zendesk integration pages were updated to use their new API.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;ui-changes&quot;&gt;UI Changes&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;The Settings page now includes the notifications settings too, and you can now find it easily on the main navigation bar.&lt;/li&gt;
  &lt;li&gt;The link to the server status page moved to the footer.&lt;/li&gt;
&lt;/ul&gt;

</content>

			
				<category term="Announcements" />
			
			

			<published>2014-05-05T00:00:00+05:00</published>
		</entry>
	
		<entry>
			<id>https://moeenahamd.github.io/2014/04/increased-cron-job-error-tolerance-count/</id>
			<title>Increased Cron Job Error Tolerance Count</title>
			<link href="https://moeenahamd.github.io/2014/04/increased-cron-job-error-tolerance-count/" rel="alternate" type="text/html" title="Increased Cron Job Error Tolerance Count" />
			<updated>2014-04-17T00:00:00+05:00</updated>

			
				
				<author>
					
						<name>Phlow</name>
					
					
					
						<uri>http://phlow.de/</uri>
					
				</author>
			
			<summary>The error tolerance of cron jobs in Cronless, the web-based cron job and port monitoring service, is now increased for all membership types. Error tolerance is the number of consecutive failures a cron job returns.</summary>
			<content type="html" xml:base="https://moeenahamd.github.io/2014/04/increased-cron-job-error-tolerance-count/">&lt;ul&gt;
  &lt;li&gt;The error tolerance of cron jobs in Cronless, the web-based cron job and port monitoring service, is now increased for all membership types.&lt;/li&gt;
  &lt;li&gt;Error tolerance is the number of consecutive failures a cron job returns before it is automatically disabled. The changes are:
    &lt;ul&gt;
      &lt;li&gt;Free memberships increased from 5 to 10.&lt;/li&gt;
      &lt;li&gt;Premium memberships increased from 10 to 100.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Please visit &lt;a href=&quot;https://cronless.com/&quot;&gt;Cronless&lt;/a&gt; to know more about the service.&lt;/p&gt;

</content>

			
				<category term="Announcements" />
			
			

			<published>2014-04-17T00:00:00+05:00</published>
		</entry>
	
		<entry>
			<id>https://moeenahamd.github.io/2014/02/paging-mysql-command-line-client/</id>
			<title>Paging in MySQL Command-Line Client</title>
			<link href="https://moeenahamd.github.io/2014/02/paging-mysql-command-line-client/" rel="alternate" type="text/html" title="Paging in MySQL Command-Line Client" />
			<updated>2014-02-04T00:00:00+05:00</updated>

			
				
				<author>
					
						<name>Phlow</name>
					
					
					
						<uri>http://phlow.de/</uri>
					
				</author>
			
			<summary>The error tolerance of cron jobs in Cronless, the web-based cron job and port monitoring service, is now increased for all membership types. Error tolerance is the number of consecutive failures a cron job returns.</summary>
			<content type="html" xml:base="https://moeenahamd.github.io/2014/02/paging-mysql-command-line-client/">
</content>

			
				<category term="Linux" />
			
				<category term="MySQL" />
			
			

			<published>2014-02-04T00:00:00+05:00</published>
		</entry>
	
		<entry>
			<id>https://moeenahamd.github.io/2014/02/paging-in-mysql-command-line-client/</id>
			<title>Paging in MySQL Command-Line Client</title>
			<link href="https://moeenahamd.github.io/2014/02/paging-in-mysql-command-line-client/" rel="alternate" type="text/html" title="Paging in MySQL Command-Line Client" />
			<updated>2014-02-04T00:00:00+05:00</updated>

			
				
				<author>
					
						<name>Phlow</name>
					
					
					
						<uri>http://phlow.de/</uri>
					
				</author>
			
			<summary>By default MySQL command-line client wraps lines in a SELECT query result and has no paging. You can solve both these problems by using the less command available in Unix/Linux systems. Entering the following command </summary>
			<content type="html" xml:base="https://moeenahamd.github.io/2014/02/paging-in-mysql-command-line-client/">&lt;p&gt;By default, the MySQL command-line client wraps lines in a SELECT query result and has no paging. You can solve both these problems by using the less command available in Unix/Linux systems.&lt;/p&gt;

&lt;p&gt;Entering the following command in the MySQL command-line client will do the trick:&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;pager less -S -X
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;The pager command lets you select a program to use as a pager. In this case we are using &lt;strong&gt;less&lt;/strong&gt;. The &lt;strong&gt;-S&lt;/strong&gt; argument instructs less to disable line wraps, and &lt;strong&gt;-X&lt;/strong&gt; instructs it disable clearing of the screen when less exits.&lt;/p&gt;

&lt;p&gt;Now when you view a SELECT query result you can scroll vertically and horizontally using the arrow keys as well as the spacebar, page up and page down keys. You can also search the query results by pressing the slash key ‘/’ and enter the term to search for. For example to search for codehill enter /codehill. And to quit press the &lt;strong&gt;‘q’&lt;/strong&gt; key.&lt;/p&gt;

&lt;p&gt;If you would like to use this as your default pager setting when you run MySQL command-line client; edit the file .my.cnf in your home directory or create it if it does not exist and enter the following:&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;pager=less -S -X
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;If you found this post useful, I’d be very grateful if you’d help it spread by sharing it. Thank you!&lt;/p&gt;
</content>

			
				<category term="Linux" />
			
				<category term="MySQL" />
			
			

			<published>2014-02-04T00:00:00+05:00</published>
		</entry>
	
		<entry>
			<id>https://moeenahamd.github.io/2014/01/checking-gzip-compressed-tar-files/</id>
			<title>Checking gzip Compressed tar Files</title>
			<link href="https://moeenahamd.github.io/2014/01/checking-gzip-compressed-tar-files/" rel="alternate" type="text/html" title="Checking gzip Compressed tar Files" />
			<updated>2014-01-22T00:00:00+05:00</updated>

			
				
				<author>
					
						<name>Phlow</name>
					
					
					
						<uri>http://phlow.de/</uri>
					
				</author>
			
			<summary>I wrote this very simple bash script to check the gzip compressed tar files generated by cPanel&apos;s backup. It attempts to extract each file individually to /dev/null and emails a list of the ones that.</summary>
			<content type="html" xml:base="https://moeenahamd.github.io/2014/01/checking-gzip-compressed-tar-files/">&lt;p&gt;I wrote this very simple bash script to check the gzip compressed tar files generated by cPanel’s backup. It attempts to extract each file individually to &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;/dev/null&lt;/code&gt; and emails a list of the ones that were not extracted successfully.&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;#!/bin/bash

path=&quot;./*.gz&quot;

found_errors=0
errors=&apos;The following backup files failed the automatic test: \n&apos;

for f in $path
do
    gunzip -c $f | tar t &amp;gt; /dev/null

    # If the exit status was not 0
    if [ $? -ne 0 ]; then
        found_errors=1
        errors=&quot;$errors\n$f&quot;
    fi
done

# If an error was found
if [ $found_errors -ne 0 ]; then
    # Email the list of files that could not be extracted/tested
    echo -e $errors | mail -s &quot;Backup Error Check&quot; &quot;admin@example.com&quot;
fi
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;Lines 8 through 17 loops through the files in the current directory with a .gz extension and extract each one using gunzip and then tar to /dev/null. If the exit status ($? in bash) is not 0 then &lt;strong&gt;gunzip&lt;/strong&gt; or &lt;strong&gt;tar&lt;/strong&gt; was not successful so the file name is concatenated to the variable error which will contain the body of the email.&lt;/p&gt;

&lt;p&gt;Lastly the if statement on line 20 will be executed if one or more of the files was not extracted successfully and will send an email containing the list of corrupted files.&lt;/p&gt;

&lt;p&gt;One last thing, the script checks the compressed files on the current directory. If you want to schedule the script to run after a backup process completes, replace the 3rd line with the following two lines and set the path to the location of your backups:&lt;/p&gt;
&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;date=`date +%Y-%m-%d`
path=&quot;/backups/whm/$date/accounts/*.gz&quot;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;This way the path will be set according to the current date, so make sure it is scheduled to run on the same day as the backup.&lt;/p&gt;

&lt;p&gt;If you found this post useful, I’d be very grateful if you’d help it spread by sharing it. Thank you!&lt;/p&gt;
</content>

			
				<category term="Linux" />
			
			

			<published>2014-01-22T00:00:00+05:00</published>
		</entry>
	
		<entry>
			<id>https://moeenahamd.github.io/2014/01/snipsmanager-Is-now-free-and-open-source/</id>
			<title>SnipsManager Is Now Free And Open Source</title>
			<link href="https://moeenahamd.github.io/2014/01/snipsmanager-Is-now-free-and-open-source/" rel="alternate" type="text/html" title="SnipsManager Is Now Free And Open Source" />
			<updated>2014-01-13T00:00:00+05:00</updated>

			
				
				<author>
					
						<name>Phlow</name>
					
					
					
						<uri>http://phlow.de/</uri>
					
				</author>
			
			<summary>SnipsManager, the PHP script for sharing source code and plain text, is now free and open source. It is now published under the Revised BSD License and is available on GitHub.</summary>
			<content type="html" xml:base="https://moeenahamd.github.io/2014/01/snipsmanager-Is-now-free-and-open-source/">&lt;p&gt;&lt;img src=&quot;/images/snipsmanager.png&quot; alt=&quot;SnipsManager Logo&quot; /&gt;&lt;/p&gt;

&lt;p&gt;SnipsManager, the PHP script for sharing source code and plain text, is now free and open source. It is now published under the Revised BSD License and is available on GitHub.&lt;/p&gt;

&lt;p&gt;Some of the features SnipsManager offers are: Syntax highlighting for 27 programming and scripting languages, protecting snippets with passwords and/or CAPTCHA, and downloading the snippet in a source file in 1 click.&lt;/p&gt;

&lt;p&gt;Please visit the links below for more details:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;/snipsmanager/&quot;&gt;SnipsManager Homepage&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;/snipsmanager/features/&quot;&gt;Features List&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;/snipsmanager/faq/&quot;&gt;Frequently Asked Questions&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;If you found this post useful, I’d be very grateful if you’d help it spread by sharing it. Thank you!&lt;/p&gt;
</content>

			
				<category term="Announcements" />
			
			

			<published>2014-01-13T00:00:00+05:00</published>
		</entry>
	
		<entry>
			<id>https://moeenahamd.github.io/2013/11/how-to-get-the-title-of-a-webpage-in-windows-forms/</id>
			<title>How to Get the Title of a Webpage in Windows Forms</title>
			<link href="https://moeenahamd.github.io/2013/11/how-to-get-the-title-of-a-webpage-in-windows-forms/" rel="alternate" type="text/html" title="How to Get the Title of a Webpage in Windows Forms" />
			<updated>2013-11-18T00:00:00+05:00</updated>

			
				
				<author>
					
						<name>Phlow</name>
					
					
					
						<uri>http://phlow.de/</uri>
					
				</author>
			
			<summary>I&apos;ve been working on a Windows Forms application that needs to, among other things, get the title of a webpage. I thought I might share it here in case someone else needs it.</summary>
			<content type="html" xml:base="https://moeenahamd.github.io/2013/11/how-to-get-the-title-of-a-webpage-in-windows-forms/">&lt;p&gt;I’ve been working on a Windows Forms application that needs to, among other things, get the title of a webpage. I thought I might share it here in case someone else needs it.&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;static string GetPageTitle(string link)
{
    try
    {
        WebClient wc = new WebClient();
        string html = wc.DownloadString(link);

        Regex x = new Regex(&quot;&quot;);
        MatchCollection m = x.Matches(html);

        if (m.Count &amp;gt; 0)
        {
            return m[0].Value.Replace(&quot;&quot;, &quot;&quot;);
        }
        else
            return &quot;&quot;;
    }
    catch (Exception ex)
    {
        Console.WriteLine(&quot;Could not connect. Error:&quot; + ex.Message);
        return &quot;&quot;;
    }
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;The function uses System.Net.WebClient to download the HTML source of the page into a string variable. Then using the regular expressions class System.Text.RegularExpressions.Regex finds the opening and closing title tags and everything in between. If a match is found the title tags in the matched string are removed by replacing them empty strings.&lt;/p&gt;

&lt;p&gt;If you found this post useful, I’d be very grateful if you’d help it spread by sharing it. Thank you!&lt;/p&gt;
</content>

			
				<category term="WinForms" />
			
			

			<published>2013-11-18T00:00:00+05:00</published>
		</entry>
	
		<entry>
			<id>https://moeenahamd.github.io/2013/06/importing-and-exporting-mysql-databases/</id>
			<title>Importing and Exporting MySQL Databases</title>
			<link href="https://moeenahamd.github.io/2013/06/importing-and-exporting-mysql-databases/" rel="alternate" type="text/html" title="Importing and Exporting MySQL Databases" />
			<updated>2013-06-19T00:00:00+05:00</updated>

			
				
				<author>
					
						<name>Phlow</name>
					
					
					
						<uri>http://phlow.de/</uri>
					
				</author>
			
			<summary>Importing and exporting MySQL databases in a Unix/Linux environment can be done easily with a single command. You can even choose to export the database&apos;s structure or data only. Exporting is done using the mysqldump </summary>
			<content type="html" xml:base="https://moeenahamd.github.io/2013/06/importing-and-exporting-mysql-databases/">&lt;p&gt;Importing and exporting MySQL databases in a Unix/Linux environment can be done easily with a single command. You can even choose to export the database’s structure or data only.&lt;/p&gt;

&lt;p&gt;Exporting is done using the &lt;strong&gt;mysqldump&lt;/strong&gt; program and importing is done using the MySQL command line client &lt;strong&gt;mysql&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;mysqldump prints out the resulting SQL to standard output and mysql gets the SQL to execute from standard input. So you will use command line redirection with each.&lt;/p&gt;

&lt;p&gt;Both programs also accept the same command line arguments. To pass the database credentials enter &lt;strong&gt;-u&lt;/strong&gt; followed by the username and &lt;strong&gt;-p&lt;/strong&gt; to prompt you for the password. And lastly the name of the database you want to import to or export from.&lt;/p&gt;

&lt;p&gt;To import a database:&lt;/p&gt;
&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;mysql -u username -p -h server_name database_name &amp;lt; dump_file
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;To export a database:&lt;/p&gt;
&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;mysqldump -u username -p database_name &amp;gt; dump_file
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;To export the database structure only:&lt;/p&gt;
&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;mysqldump --no-data -u username -p database_name &amp;gt; dump_file
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;To export the database data only:&lt;/p&gt;
&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;mysqldump --no-create-info -u username -p database_name &amp;gt; dump_file
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;If you found this post useful, I’d be very grateful if you’d help it spread by sharing it. Thank you!&lt;/p&gt;
</content>

			
				<category term="Linux" />
			
				<category term="MySQL" />
			
			

			<published>2013-06-19T00:00:00+05:00</published>
		</entry>
	
		<entry>
			<id>https://moeenahamd.github.io/2013/06/navigating-mysql-databases-and-tables/</id>
			<title>Navigating MySQL Databases and Tables</title>
			<link href="https://moeenahamd.github.io/2013/06/navigating-mysql-databases-and-tables/" rel="alternate" type="text/html" title="Navigating MySQL Databases and Tables" />
			<updated>2013-06-18T00:00:00+05:00</updated>

			
				
				<author>
					
						<name>Phlow</name>
					
					
					
						<uri>http://phlow.de/</uri>
					
				</author>
			
			<summary>Here is a list of MySQL&apos;s command line client commands to navigate through the databases and their tables. First run the client program by entering the following at the command line: The -u option is</summary>
			<content type="html" xml:base="https://moeenahamd.github.io/2013/06/navigating-mysql-databases-and-tables/">&lt;p&gt;Here is a list of MySQL’s command line client commands to navigate through the databases and their tables.&lt;/p&gt;

&lt;p&gt;First run the client program by entering the following at the command line:&lt;/p&gt;
&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;mysql -u root -p
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;The -u option is for passing the username. So change root to the username you have access to. And the -p options prompts you for your password. You can omit it if your username does not have a password. Now at the mysql&amp;gt; prompt try the following commands:&lt;/p&gt;

&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;strong&gt;show databases;&lt;/strong&gt;&lt;/td&gt;
      &lt;td&gt;List the names of the databases on the server.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;strong&gt;use database_name;&lt;/strong&gt;&lt;/td&gt;
      &lt;td&gt;Select a database to access its contents. e.g.: &lt;em&gt;use college&lt;/em&gt;;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;strong&gt;show tables;&lt;/strong&gt;&lt;/td&gt;
      &lt;td&gt;List the names of tables in the currently selected database.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;strong&gt;desc table_name;&lt;/strong&gt;&lt;/td&gt;
      &lt;td&gt;List the structure of the table: field names, data types, and attributes. e.g.: &lt;em&gt;desc student_courses;&lt;/em&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;strong&gt;show indexes from table_name;&lt;/strong&gt;&lt;/td&gt;
      &lt;td&gt;Display a detailed list of the indexes of a table. e.g.: &lt;em&gt;show indexes from student_courses;&lt;/em&gt;&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;If you found this post useful, I’d be very grateful if you’d help it spread by sharing it. Thank you!&lt;/p&gt;

</content>

			
				<category term="MySQL" />
			
			

			<published>2013-06-18T00:00:00+05:00</published>
		</entry>
	
</feed>